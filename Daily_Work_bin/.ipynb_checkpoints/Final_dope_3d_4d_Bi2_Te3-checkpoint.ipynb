{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuous-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here kkr_imp_wc will be run from uuid: '23b13d9d-6e02-46c7-b3ac-17033b205b19'\n",
    "## which is the converge kkr calculation for host Bi2Te3 TI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chief-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile name :  default\n",
      "profile database host name :  localhost\n",
      "default user :  r.mozumder@fz-juelich.de\n"
     ]
    }
   ],
   "source": [
    "#load aiida environment and connect to database\n",
    "from aiida import load_profile\n",
    "\n",
    "profile = load_profile()\n",
    "print('profile name : ',profile.name)\n",
    "print('profile database host name : ',profile.database_hostname)\n",
    "print('default user : ',profile.default_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classes and functions\n",
    "from aiida.orm import Code, Dict, load_node, StructureData\n",
    "# from aiida.orm import\n",
    "from aiida_kkr.tools import kkrparams\n",
    "from aiida.engine import submit\n",
    "from aiida_kkr.tools import kkrparams, plot_kkr\n",
    "from aiida_kkr.workflows import kkr_flex_wc, kkr_imp_dos_wc, kkr_dos_wc\n",
    "\n",
    "from aiida.orm import load_group, WorkChainNode\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifty-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classes and functions\n",
    "from aiida.orm import CifData, Code, Dict, load_node, StructureData \n",
    "from aiida.orm import (Group, load_group, load_node, load_code, groups,\n",
    "                      WorkChainNode)\n",
    "from aiida.engine import submit\n",
    "from aiida.common.exceptions import NotExistent\n",
    "from aiida_kkr.workflows import kkr_imp_sub_wc, kkr_imp_dos, kkr_imp_wc, kkr_startpot_wc\n",
    "import numpy as np\n",
    "from aiida_kkr.calculations import KkrimpCalculation, VoronoiCalculation\n",
    "import matplotlib.pyplot as plt\n",
    "from aiida_kkr.tools.common_workfunctions import get_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "future-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the metadata options and code\n",
    "metadata_option_1 = {'max_wallclock_seconds': 36000,'resources': \n",
    "               {'tot_num_mpiprocs': 48, 'num_machines': 1},\n",
    "              'custom_scheduler_commands': \n",
    "              '#SBATCH --account=jara0191\\n\\nulimit -s unlimited; export OMP_STACKSIZE=2g',\n",
    "              'withmpi': True\n",
    "                    }\n",
    "\n",
    "oscar_matadata = {'max_wallclock_seconds': 8*60*60,\n",
    "                  'resources':{'tot_num_mpiprocs': 12, \n",
    "                  'num_machines': 4},\n",
    "                  'custom_scheduler_commands': '#SBATCH -u mozumder -p oscar\\n\\nulimit -s unlimited; export OMP_STACKSIZE= 2g',\n",
    "                  'withmpi':True\n",
    "                 }\n",
    "voro_code = Code.get_from_string('voro@claix18_init')\n",
    "kkr_code = Code.get_from_string('kkr@claix18_init')\n",
    "kkrimp_code = Code.get_from_string('kkrflex@claix18_init')\n",
    "iffslurm_voro = Code.get_from_string('voro@iffslurm')\n",
    "iffslurm_kkr= Code.get_from_string('kkr@iffslurm')\n",
    "iffslurm_kkrimp= Code.get_from_string('kkrflex@iffslurm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "veterinary-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the converged kkr host calculation and the remote foder\n",
    "Bi2Te3_conv_kkr = load_node('23b13d9d-6e02-46c7-b3ac-17033b205b19')\n",
    "remote_last_calc_folder = Bi2Te3_conv_kkr.outputs.remote_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-machinery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lyric-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of workflow: 0.8.1\n"
     ]
    }
   ],
   "source": [
    "# Runing the host host_gf_writeout step\n",
    "###For Europium: 63\n",
    "#Node: 65870, 65556(failed), 67586 for Eu, ilayer-3, wtihout magnetic init\n",
    "\n",
    "### For Iron:26\n",
    "#Node: 65607, 65766(failed), 65806, 65822 (failed) for Iron:26, ilayer=3\n",
    "\n",
    "### For Nickel: Ni(28)\n",
    "#Node: 65623 (failed),  65854(failed)  for Ni ilayer=3\n",
    "\n",
    "### For Cobalt(27)\n",
    "#Node: 65639(failed), 65838  for Co, ilayer=3\n",
    "\n",
    "# setup the builder inputs\n",
    "label = 'Eu:'+'Bi2Te3'\n",
    "description = ('imp:Eu_repalced_atom:Bi_,'+ \n",
    "               'Struc:uuid:c1626804-5b71-450c-91c4-aa7197d85279_'+\n",
    "               'kkr_conv:23b13d9d-6e02-46c7-b3ac-17033b205b19')\n",
    "\n",
    "\n",
    "imp_info = {'Rcut': 4.0, 'Zimp': [63.0], 'ilayer_center': 3}\n",
    "\n",
    "options, settings_imp, settings_vorostart = kkr_imp_wc.get_wf_defaults()\n",
    "settings_imp['mag_init'] = True\n",
    "settings_imp['retrieve_kkrflex'] = False\n",
    "settings_imp['convergence_criterion'] = 1e-8\n",
    "settings_imp['HFIELD']= [0.02, 5]\n",
    "settings_imp['nsteps'] = 120 \n",
    "settings_imp['strmix'] = 0.02\n",
    "settings_imp['aggrmix'] = 0.05\n",
    "settings_imp['threshold_aggressive_mixing'] = 0.01 ## Error: This key realy comes as QBOUND\n",
    "#settings_imp['XC'] = 'LDA-VWN'\n",
    "#settings_imp['KVREL'] = 1\n",
    "#settings_imp['NCHEB'] = 12\n",
    "#settings_imp['NPAN_EQ'] = 7\n",
    "#settings_imp['NPAN_LOG'] = 17\n",
    "\n",
    "#settings_imp['ITDBRY'] = 30\n",
    "\n",
    "#settings_imp['natom_in_cls_min'] = 35\n",
    "## for gf writeout step\n",
    "params_kkr_overwrite = {'BZDIVIDE': [80,80,80],\n",
    "                        'NSHELD': 2500,\n",
    "                        'LMAX': 3,\n",
    "                        'KPOIBZ': 1000000\n",
    "                       }\n",
    "\n",
    "builder_kkr_imp = kkr_imp_wc.get_builder()\n",
    "\n",
    "builder_kkr_imp.metadata.label = label\n",
    "builder_kkr_imp.metadata.description = description\n",
    "\n",
    "builder_kkr_imp.impurity_info = Dict(dict=imp_info)\n",
    "builder_kkr_imp.remote_data_host = remote_last_calc_folder\n",
    "builder_kkr_imp.wf_parameters = Dict(dict=settings_imp)\n",
    "\n",
    "##----------------------\n",
    "# This option is added to run the imp_kkr_wc with large BZDIVIDE\n",
    "# Otherwise not need\n",
    "\n",
    "builder_kkr_imp.params_kkr_overwrite=Dict(dict=params_kkr_overwrite)\n",
    "##----------------------\n",
    "\n",
    "## To run the calc in the claix18\n",
    "\n",
    "builder_kkr_imp.voronoi = voro_code\n",
    "builder_kkr_imp.kkr = kkr_code\n",
    "builder_kkr_imp.kkrimp = kkrimp_code\n",
    "builder_kkr_imp.options = Dict(dict=metadata_option_1)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## To run the calc in the iffslurm\n",
    "#builder_kkr_imp.voronoi = iffslurm_voro\n",
    "#builder_kkr_imp.kkr = iffslurm_kkr\n",
    "#builder_kkr_imp.kkrimp = iffslurm_kkrimp\n",
    "#builder_kkr_imp.options = Dict(dict=oscar_matadata)\n",
    "\n",
    "## -------------------------------\n",
    "# First kkr_imp is started here\n",
    "kkr_imp_start = submit(builder_kkr_imp)\n",
    "\n",
    "\n",
    "\n",
    "# ilayer-3, pk:16100 uuid: 94c02cd3-57c8-4211-92bf-1478f2b93b68\n",
    "# ilayer-4, pk:16637, uiid:'b146795e-3c0d-435d-924c-60834fc855a5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "oriental-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.engine import workfunction\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forty-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This is the edited part and my be final part\n",
    "## By this function a long list of the single kkr_imp_wc could be run.\n",
    "## Previous successful kkr_imp_wc process\n",
    "\n",
    "from aiida.engine import workfunction\n",
    "Fe_Bi2Te3_wc = load_node(16637)\n",
    "host_gf = Fe_Bi2Te3_wc.outputs.remote_data_gf\n",
    "imp_info_old = Fe_Bi2Te3_wc.inputs.impurity_info.get_dict()\n",
    "options = Fe_Bi2Te3_wc.inputs.options\n",
    "\n",
    "## TODO: Try to add the group_Id to load an existing group\n",
    "\n",
    "# \n",
    "def submition_bunch_wc(parent_wc, imp_num_each_wc=None, imp_Z_list=None,builder_options=None,\n",
    "                       ilayers=[],label=None,description=None, imp_setup_dict_list=None,\n",
    "                       group_label= None, group_description=None,\n",
    "                       ):\n",
    "    import time as t\n",
    "    from aiida.common.exceptions import UniquenessError, NotExistent\n",
    "    from aiida.common.constants import elements as elmt\n",
    "    from aiida.orm import (CifData, Code, Dict, load_node,load_group, StructureData,\n",
    "                          Group)\n",
    "\n",
    "    \"\"\"\n",
    "    params:\n",
    "    parent_wc : (WorkchainNode, required= True): To get the impurity_info where the host\n",
    "                atom will be repalced by the desired imp atom, rurun the WC.\n",
    "                To get the host_gf \n",
    "    imp_num_each_wc : (int, required= False) : It represents impurity atom number palced in \n",
    "                     impurity info dict(). Either imp_num_each_wc or imp_setup_dict_list must\n",
    "                     be given.\n",
    "    imp_Z_list : (list, required= Flase): It contains list of all zimp for restarting the \n",
    "                 parent_imp_wc. Either imp_setup_dict_list or imp_Z_list have to be in param.\n",
    "    builder_options : (dict or Dict, required = False): To setup the cluster options.\n",
    "                      If not given parent_wc.option will be utilise\n",
    "    ilayers: (list, required=False): This is the list of ilayers to run over the ilayer.\n",
    "            Keep in mind that ilayer value should be the same as in the impurity info in the parent wc.  \n",
    "\n",
    "    \"\"\"\n",
    "## Todo: check group node, from successfull wc node, will be automatic created or not\n",
    "## Todo: If not the try to add this feature\n",
    "##\n",
    "\n",
    "# To set the builder options\n",
    "    if builder_options == None:\n",
    "        try:\n",
    "            options = parent_wc.inputs.options\n",
    "        except NotExistent:\n",
    "            msg = 'Neither builder_options is given nor it is found in parent_calculation'\n",
    "            return msg\n",
    "    else:\n",
    "        options= builder_options\n",
    "        print('Option is collected from params')\n",
    "\n",
    "    # Collect required node from parent_wc\n",
    "    imp_dict = parent_wc.inputs.impurity_info.get_dict()\n",
    "    host_gf = parent_wc.outputs.remote_data_gf\n",
    "    is_imp_dict_available = False\n",
    "    #####\n",
    "    bin_success_info = {}\n",
    "    all_possible_dict = {}\n",
    "    all_succeful_dict = {} \n",
    "    all_imp_remaider ={}\n",
    "    ### \n",
    "    \n",
    "    # create group and store it\n",
    "    try :\n",
    "        existed_group= load_group(group_label)\n",
    "        print('The given Group exists in DB.  So new successfull Nodes'\n",
    "              + 'will be added with the group. Group pk {}'.format(existed_group.pk))\n",
    "        created_group = existed_group\n",
    "    except:\n",
    "        if group_label == None:\n",
    "            group_label='Restarted_wc_from_uuid_{}'.format(parent_wc.uuid)\n",
    "        if group_description == None:\n",
    "            group_description='The parent wc impurity info {}'.format(imp_dict)\n",
    "        created_group=Group(label=group_label, description=group_description)\n",
    "        created_group.store()\n",
    "\n",
    "   \n",
    "    ## To create all the possible imp_settings  \n",
    "    all_possible_dict = {} ## All the posssible_dict combination\n",
    "    all_succeful_dict = {} ## To collect all the successfull imp_dict\n",
    "    all_imp_remaider = {} ## The leftover imp_dict without sucessfull imp_dict\n",
    "    \n",
    "    # Create dict of impurity_info dict either from imp_setup_dict_list \n",
    "    # or by combining imp_Z_list, ilayers \n",
    "    if imp_setup_dict_list==None:\n",
    "        print(\"No impurity setup is provided. The impurity setup will be created as follows \\n\\\n",
    "              Combination among all the atoms in the imp_Z_list consisting imp_num_each_wc\\n\\\n",
    "              atom in each group. Each group will be set in the ilayers position. A \\n\\\n",
    "              combination among the ilayers element will be consider, each group will \\n\\\n",
    "              have the same length as numbe of atoms in each atom group\" )\n",
    "    \n",
    "        if imp_num_each_wc == 1:\n",
    "            ## order the dict\n",
    "            dict_order = 0\n",
    "            for Z in imp_Z_list[:] :\n",
    "                    for i_layer in ilayers[:]:\n",
    "                        dict_order += 1\n",
    "                        imp_dict['Zimp'] = Z\n",
    "#                         imp_dict['ilayer_center'] = i_layer\n",
    "                        copy_imp_dict = imp_dict.copy()\n",
    "                        all_possible_dict[dict_order] = copy_imp_dict\n",
    "\n",
    "            all_imp_remaider = all_possible_dict.copy()\n",
    "            is_imp_dict_available = True\n",
    "            \n",
    "    elif isinstance(imp_setup_dict_list, list):\n",
    "        dict_order = 0\n",
    "        for i in range(len(imp_setup_dict_list)):\n",
    "            all_possible_dict[dict_order] = imp_setup_dict_list[i] ## All the posssible_dict combination\n",
    "            dict_order += 1 \n",
    "        is_imp_dict_available = True\n",
    "        all_imp_remaider = all_possible_dict.copy()\n",
    "    else :\n",
    "        is_imp_dict_available = False\n",
    "        return 'No impurity info is given by the imp_setup_dict_list nor imp_num_each_wc'\n",
    "    \n",
    "    ##  some pre assumed or pre known values \n",
    "    ####-------------------------\n",
    "    # Change the workflow parameter here for higher\n",
    "    kkr_imp_wc_dict = parent_wc.inputs.wf_parameters.get_dict()\n",
    "    kkr_imp_wc_dict['nsteps'] = 300\n",
    "    kkr_imp_wc_dict['convergence_criterion'] = 1e-07\n",
    "    kkr_imp_wc_dict['retrieve_kkrflex'] = False\n",
    "    \n",
    "    ####-------------------------\n",
    "    if is_imp_dict_available :\n",
    "        # To submit max number of wc at one time\n",
    "        max_wc_submition = 8\n",
    "        stop_here = False\n",
    "        bin_success_info = {}\n",
    "        bin_= {}   ## Use it as submitted imp info\n",
    "        ## wc counting info\n",
    "        builder_iter = 0 ## for tracking the submitted wc\n",
    "        finished_iter = 0 ## tracking the finished wc\n",
    "        total_wc = dict_order ## Total number of wc to be submitted\n",
    "        \n",
    "        # \n",
    "        if max_wc_submition > total_wc:\n",
    "            max_wc_submition = total_wc\n",
    "        created_group_node_list = list(created_group.nodes)\n",
    "        group_node_label_list = [node.label for node in created_group_node_list[:]]\n",
    "        ## To run all the calcualtion according to the all_possible_dict\n",
    "        for order, imp_settings in all_possible_dict.items():\n",
    "            ## stop_here stop all the sumbmition function if exit_status != 0\n",
    "            if stop_here==True:\n",
    "                break\n",
    "                print('At least work chain is finished with '+\n",
    "                      'exit_code not 0, and stop here break 000')\n",
    "\n",
    "    ####---------------------------------------------------\n",
    "            zatom = imp_settings['Zimp']\n",
    "            imp_symbol = elmt[zatom]['symbol']\n",
    "            wc_label = imp_symbol + ':Bi2Te3'\n",
    "            print(wc_label)\n",
    "          \n",
    "            new_imp_dict = imp_settings.copy()\n",
    "            ## step for sumitting the one job\n",
    "            builder = parent_wc.get_builder_restart()\n",
    "            # To remove 'remote_data_host' from builder dict\n",
    "            builder.pop('remote_data_host')\n",
    "            builder.remote_data_gf = host_gf\n",
    "            builder.wf_parameters = Dict(dict=kkr_imp_wc_dict)\n",
    "            builder.impurity_info = Dict(dict=new_imp_dict)\n",
    "            builder.metadata.label = str(wc_label)\n",
    "            builder.options = options\n",
    "            builder_iter += 1\n",
    "#             submition = submit(builder)\n",
    "            t.sleep(30)\n",
    "            ## Here the bin ony takes upto eight elements of group\n",
    "            bin_element = {'pk': submition.pk,\n",
    "                                  'uuid': submition.uuid,\n",
    "                                  'exit_status': None,\n",
    "                                  'track_num': order, 'imp_info' :new_imp_dict}\n",
    "            bin_[order] = bin_element\n",
    "            ## The keep the activated wc equal or below the max_wc_submition\n",
    "            ## that is the maximum work-chain to be in running \n",
    "            while ((builder_iter-finished_iter >= max_wc_submition) or (total_wc == builder_iter) or (stop_here==True) ):\n",
    "\n",
    "                t.sleep(120)\n",
    "#                 print('sleeping for 120 second starting of the while loop')\n",
    "                bin_success_wc = []\n",
    "                bin_failure_wc = []\n",
    "    \n",
    "                if (len(bin_) == 0) :\n",
    "                    ## Break the while loop here\n",
    "                    break\n",
    "                    \n",
    "                for calc_order, sub_info in bin_.items():\n",
    "                    wc_pk = bin_[calc_order]['pk']\n",
    "                    wc_node = load_node(wc_pk)\n",
    "                    if wc_node.is_finished == True:\n",
    "                        if wc_node.exit_status == 0:\n",
    "                            print('one clalc is finished')\n",
    "                            bin_[calc_order]['exit_status']=0\n",
    "\n",
    "                            ## To add the dict as a successfull dict\n",
    "                            copy_to_success = all_possible_dict[calc_order].copy()\n",
    "                            all_succeful_dict[calc_order] = (copy_to_success)\n",
    "\n",
    "                            ## To delete the dict from the all_imp_remainder as it is the copy of all_possible_dict\n",
    "                            all_imp_remaider.pop(calc_order)\n",
    "\n",
    "                            ## To collect the successfull calc info such as pk, uuid\n",
    "                            copy_sucess_info = bin_[calc_order].copy()\n",
    "                           # before storing the node check is node is available there\n",
    "                            if wc_node.label in group_node_label_list[:]:\n",
    "                                print('The wc_node pk : {} and label {} is already exist on the group {}'.format(wc_node.pk, wc_node.label, created_group.label))\n",
    "                                created_group.add_nodes(wc_node)\n",
    "                            else:\n",
    "                                created_group.add_nodes(wc_node)\n",
    "                                \n",
    "                            bin_success_info[calc_order] = copy_sucess_info\n",
    "                            ## To reduce the dict from the bin_ as it is boundary that can be submit wc at one time\n",
    "                            bin_success_wc.append(calc_order)\n",
    "                            finished_iter += 1\n",
    "                        else :\n",
    "                            bin_failure_wc.append(calc_order)\n",
    "                            stop_here = True\n",
    "                            print('---exit_status is not 0. So, one inconistency in wc {} is found'.format(wc_pk))\n",
    "\n",
    "                ## To delete the element from bin_ as this wc are finished \n",
    "                ## and create the new space for others\n",
    "                if (bin_success_wc != []):\n",
    "                    for i in bin_success_wc[:]:\n",
    "                        bin_.pop(i)\n",
    "                        \n",
    "                if (bin_failure_wc != []):\n",
    "                    for i in bin_failure_wc[:]:\n",
    "                        bin_.pop(i)\n",
    "                \n",
    "    return all_possible_dict, all_succeful_dict, all_imp_remaider, bin_success_info\n",
    "\n",
    "\n",
    "imp_num_each_wc = 1\n",
    "i_layers = [3]\n",
    "d_elmt_zatom = [*range(29,31, 1)] + [*range(39,49, 1)]\n",
    "builder_options = Dict(dict=metadata_option_1)\n",
    "\n",
    "group_label = '3d_4d_dopants_Bi2Te3_ilayer4'\n",
    "\n",
    "imp_setup_dict_list = [{'Rcut': 4.0, 'Zimp': 27, 'ilayer_center': 4}]\n",
    "\n",
    "# all_possible_dict, all_succeful_dict, all_imp_remaider, bin_success_info = submition_bunch_wc(parent_wc=Fe_Bi2Te3_wc, builder_options=builder_options, \n",
    "#                                                                                               imp_setup_dict_list=imp_setup_dict_list, \n",
    "#                                                                                               group_label=group_label)\n",
    "\n",
    "# all_possible_dict, all_succeful_dict, all_imp_remaider, bin_success_info  = submition_bunch_wc(parent_wc= Fe_Bi2Te3_wc, imp_num_each_wc= 1,\n",
    "#                                                                                                imp_Z_list= d_elmt_zatom,builder_options= builder_options,\n",
    "#                                                                                                ilayers= i_layers, group_label=group_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "french-arbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: {'Rcut': 4.0, 'Zimp': 30, 'ilayer_center': 3},\n",
       " 3: {'Rcut': 4.0, 'Zimp': 39, 'ilayer_center': 3},\n",
       " 4: {'Rcut': 4.0, 'Zimp': 40, 'ilayer_center': 3},\n",
       " 6: {'Rcut': 4.0, 'Zimp': 42, 'ilayer_center': 3},\n",
       " 5: {'Rcut': 4.0, 'Zimp': 41, 'ilayer_center': 3},\n",
       " 1: {'Rcut': 4.0, 'Zimp': 29, 'ilayer_center': 3},\n",
       " 7: {'Rcut': 4.0, 'Zimp': 43, 'ilayer_center': 3},\n",
       " 8: {'Rcut': 4.0, 'Zimp': 44, 'ilayer_center': 3},\n",
       " 9: {'Rcut': 4.0, 'Zimp': 45, 'ilayer_center': 3},\n",
       " 11: {'Rcut': 4.0, 'Zimp': 47, 'ilayer_center': 3},\n",
       " 12: {'Rcut': 4.0, 'Zimp': 48, 'ilayer_center': 3},\n",
       " 10: {'Rcut': 4.0, 'Zimp': 46, 'ilayer_center': 3}}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_succeful_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adverse-vampire",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotExistentAttributeError",
     "evalue": "Node<21270> does not have an output with link label 'converged_potential'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotExistent\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/utils/managers.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_by_link_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotExistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/utils/managers.py\u001b[0m in \u001b[0;36m_get_node_by_link_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_incoming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_by_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outgoing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_node_by_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/utils/links.py\u001b[0m in \u001b[0;36mget_node_by_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatching_entry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotExistent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'no neighbor with the label {label} found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotExistent\u001b[0m: no neighbor with the label converged_potential found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotExistentAttributeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7c8abcf47986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata_option_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mimp_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_kkrimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpurity_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mkkrimp_sfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_kkrimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged_potential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Now to submit the kkr_dos_wc node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/utils/managers.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Otherwise, the exception is not caught by `getattr` and is propagated, instead of returning the default.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_incoming\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotExistentAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Node<{self._node.pk}> does not have an {prefix} with link label '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotExistentAttributeError\u001b[0m: Node<21270> does not have an output with link label 'converged_potential'"
     ]
    }
   ],
   "source": [
    "## This Part is intended to run the kkr_imp_dos_wc from the previous kkr_imp_wc\n",
    "# Inputs:\n",
    "# Features:\n",
    "\n",
    "# Trying to run single imp DOS calculation\n",
    "\n",
    "parent_kkrimp = load_node(21270)\n",
    "\n",
    "## Preparation the inputs\n",
    "dos_wf_parameters = {'dos_run': True,\n",
    "                     'ef_shift': 0.0,\n",
    "                     'dos_params': {'emax': 1.0,\n",
    "                      'emin': -1.0,\n",
    "                      'kmesh': [30, 30, 30],\n",
    "                      'nepts': 96,\n",
    "                      'tempr': 200.0,\n",
    "                      'RCLUSTZ': 6.0}}\n",
    "\n",
    "code = Code()\n",
    "kkr_code = code.get_from_string('kkr@claix18_init')\n",
    "kkrimp_code = code.get_from_string('kkrflex@claix18_init')\n",
    "options = metadata_option_1\n",
    "imp_info = parent_kkrimp.inputs.impurity_info\n",
    "kkrimp_sfd = parent_kkrimp.outputs.converged_potential\n",
    "\n",
    "# Now to submit the kkr_dos_wc node\n",
    "kkrdoswc = kkr_imp_dos_wc.get_builder()\n",
    "\n",
    "kkrdoswc.kkr = kkr_code\n",
    "kkrdoswc.kkrimp = kkrimp_code\n",
    "kkrdoswc.impurity_info = imp_info\n",
    "# kkrdoswc.imp_pot_sfd = kkrimp_sfd\n",
    "kkrdoswc.options = Dict(dict=options)\n",
    "kkrdoswc.wf_parameters = Dict(dict=dos_wf_parameters)\n",
    "# kkrdoswc_activate = submit(kkrdoswc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acceptable-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sc:Bi2Te3_dos_(-1,1)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_kkrimp = load_node(21270)\n",
    "dos_wf_parameters = { 'dos_params': {'emax': 1.0,\n",
    "                          'emin': -1.0,\n",
    "                          'nepts': 96}\n",
    "                        }\n",
    "def dos_bunch_from_pre_dos(pre_dos_node_list: list=None, dos_wf_parameters_dict: dict = {})\n",
    "    ## To define some tracking number\n",
    "    tot_dos_num = 0\n",
    "    tot_run_num = 0\n",
    "    tot_fin_fai_num = 0\n",
    "    max_runing\n",
    "    for parent_kkrimp in pre_dos_node_list[:]:\n",
    "    \n",
    "    dos_wf_parameters = dos_wf_parameters_dict\n",
    "    dos_restart = parent_kkrimp.get_builder_restart()\n",
    "    dos_restart.wf_parameters = Dict(dict=dos_wf_parameters)\n",
    "    dos_restart.metadata.label = \"More resulation near the Fermi_Energy_label (-1,1)\"\n",
    "    # submission = submit(dos_restart) # 58991\n",
    "    submission.label\n",
    "    # dos_restart.wf_parameters.get_dict()\n",
    "    # parent_kkrimp.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-eugene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "honey-adolescent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18917\n",
      "Mn:Bi2Te3\n",
      "dos_pk :  59422\n",
      "18896\n",
      "Cr:Bi2Te3\n",
      "dos_pk :  59426\n",
      "18875\n",
      "V:Bi2Te3\n",
      "dos_pk :  59432\n",
      "18853\n",
      "Ti:Bi2Te3\n",
      "dos_pk :  59440\n",
      "19012\n",
      "Ni:Bi2Te3\n",
      "dos_pk :  59449\n",
      "18938\n",
      "Fe:Bi2Te3\n",
      "dos_pk :  59459\n",
      "19257\n",
      "Y:Bi2Te3\n",
      "dos_pk :  59466\n",
      "19226\n",
      "Zn:Bi2Te3\n",
      "dos_pk :  59476\n",
      "19303\n",
      "Zr:Bi2Te3\n",
      "dos_pk :  59484\n",
      "19180\n",
      "Cu:Bi2Te3\n",
      "dos_pk :  59496\n",
      "19364\n",
      "Nb:Bi2Te3\n",
      "dos_pk :  59504\n",
      "19410\n",
      "Mo:Bi2Te3\n",
      "dos_pk :  59516\n",
      "19456\n",
      "Tc:Bi2Te3\n",
      "dos_pk :  59523\n",
      "19597\n",
      "Rh:Bi2Te3\n",
      "dos_pk :  59530\n",
      "19720\n",
      "Cd:Bi2Te3\n",
      "dos_pk :  59543\n",
      "19642\n",
      "Pd:Bi2Te3\n",
      "dos_pk :  59549\n",
      "19551\n",
      "Ru:Bi2Te3\n",
      "dos_pk :  59559\n",
      "19689\n",
      "Ag:Bi2Te3\n",
      "dos_pk :  59571\n"
     ]
    }
   ],
   "source": [
    "##  To submit the a bunch of doc wc\n",
    "def dos_wc_branch(parent_kkrimp_wc_group=None, parent_kkrimp_wc_list=[]):\n",
    "    from aiida.engine import submit\n",
    "    import time as t\n",
    "    ## Preparation the inputs\n",
    "    dos_wf_parameters = { 'dos_params': {'emax': 1.0,\n",
    "                      'emin': -1.0,\n",
    "                      'nepts': 96}\n",
    "                    }\n",
    "    if parent_kkrimp_wc_list!= []:\n",
    "        wc_list= parent_kkrimp_wc_list\n",
    "    else:\n",
    "       \n",
    "        parent_kkrimp_wc_group = load_group(parent_kkrimp_wc_group)\n",
    "        wc_list = list(parent_kkrimp_wc_group.nodes)\n",
    "\n",
    "   \n",
    "    for node in wc_list[1:]:\n",
    "        print(node.pk)\n",
    "        print(node.label)\n",
    "        parent_kkrimp = load_node(node.pk)\n",
    "\n",
    "        code = Code()\n",
    "        kkr_code = code.get_from_string('kkr@claix18_init')\n",
    "        kkrimp_code = code.get_from_string('kkrflex@claix18_init')\n",
    "        options = metadata_option_1\n",
    "        imp_info = parent_kkrimp.inputs.impurity_info\n",
    "        kkrimp_sfd = parent_kkrimp.outputs.converged_potential\n",
    "        label = parent_kkrimp.label + 'dos_(-1,1)'#'aiid#'aiida_kkr.workflows.gf_writeout.kkr_flex_wc':#'aiida_kkr.workflows.gf_writeout.kkr_flex_wc':#'aiida_kkr.workflows.gf_writeout.kkr_flex_wc':a_kkr.workflows.gf_writeout.kkr_flex_wc':\n",
    "        # Now to submit the kkr_dos_wc node\n",
    "        kkrdoswc = kkr_imp_dos_wc.get_builder()\n",
    "\n",
    "        kkrdoswc.kkr = kkr_code\n",
    "        kkrdoswc.kkrimp = kkrimp_code\n",
    "        kkrdoswc.impurity_info = imp_info\n",
    "        kkrdoswc.imp_pot_sfd = kkrimp_sfd\n",
    "        kkrdoswc.options = Dict(dict=options)\n",
    "        kkrdoswc.wf_parameters = Dict(dict=dos_wf_parameters)\n",
    "        kkrdoswc.metadata.label = label\n",
    "#         out_wc = submit(kkrdoswc)\n",
    "        print('dos_pk : ',out_wc.pk)\n",
    "    \n",
    "    \n",
    "parent_kkrimp_wc = load_group(91)\n",
    "dos_wc_branch(parent_kkrimp_wc_group= 91)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-interface",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "subject-denver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aiida_kkr.workflows.kkr_imp.kkr_imp_wc"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_n = load_node(18833)\n",
    "load_n.node_type =='process.workflow.workchain.WorkChainNode.'\n",
    "load_n.process_class #== 'aiida_kkr.workflows.kkr_imp.kkr_imp_dos_wc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "asian-mouse",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1e6c96d7bc2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutgoing_wc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged_potential\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwc_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutgoing_wc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outgoing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutgoing_wc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutgoing_wc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mwc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutgoing_wc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'process.workflow.workchain.WorkChainNode.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#         outgoing_wc = [ wc for wc in outgoing_wc[:] if wc.node.process_class=='aiida_kkr.workflows.kkr_imp_dos.kkr_imp_dos_wc']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1e6c96d7bc2f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutgoing_wc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged_potential\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwc_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutgoing_wc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outgoing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutgoing_wc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutgoing_wc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mwc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutgoing_wc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'process.workflow.workchain.WorkChainNode.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#         outgoing_wc = [ wc for wc in outgoing_wc[:] if wc.node.process_class=='aiida_kkr.workflows.kkr_imp_dos.kkr_imp_dos_wc']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "wc_dos_list = []\n",
    "loaded_group = load_group(91)\n",
    "wc_list = list(loaded_group.nodes)\n",
    "for node in wc_list[:]:\n",
    "    loaded_node = load_node(node.pk)\n",
    "    dos_wc = False\n",
    "    while(not dos_wc):\n",
    "        outgoing_wc = [ i.outputs.converged_potential for i in wc_list[:]]\n",
    "        outgoing_wc = [ i.get_outgoing().all() for i in outgoing_wc]\n",
    "        outgoing_wc = [ wc for wc in outgoing_wc[:] if wc.node.node_type=='process.workflow.workchain.WorkChainNode.']\n",
    "#         outgoing_wc = [ wc for wc in outgoing_wc[:] if wc.node.process_class=='aiida_kkr.workflows.kkr_imp_dos.kkr_imp_dos_wc']\n",
    "        \n",
    "        print(outgoing_wc)\n",
    "        dos_wc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb1 = QueryBuilder()\n",
    "node_list = qb1.append(WorkChainNode,\n",
    "          filters={\n",
    "               'and':[\n",
    "                   {'attributes.process_label':'combine_imps_wc'},\n",
    "                   {'attributes.exit_status':{'!in':[0]}}\n",
    "                  \n",
    "               ],\n",
    "              'id':{'>':63952},\n",
    "              'attributes.process_label':'combine_imps_wc',\n",
    "#\n",
    "              \n",
    "          }\n",
    "         ).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-seeking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pacific-universe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tutorial-colorado",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "banned-transsexual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<WorkChainNode: uuid: 34405c8d-ad01-43dd-a2ff-f31d6932cea2 (pk: 65607) (aiida.workflows:kkr.imp)>,\n",
       " <WorkChainNode: uuid: a28d5412-2ee4-4c87-a17b-8da4d94992c2 (pk: 65623) (aiida.workflows:kkr.imp)>,\n",
       " <WorkChainNode: uuid: f2723616-600f-4dfa-82fe-4f2989a1a386 (pk: 65639) (aiida.workflows:kkr.imp)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-given",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-annex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-study",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-journalism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-spider",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiiDA",
   "language": "python",
   "name": "aiida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
