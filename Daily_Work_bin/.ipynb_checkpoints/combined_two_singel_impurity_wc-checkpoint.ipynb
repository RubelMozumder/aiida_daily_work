{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spoken-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the aiida profile\n",
    "from aiida import load_profile\n",
    "aiida_profile = load_profile()\n",
    "aiida_profile.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solved-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the some require packages and module\n",
    "from aiida_kkr.workflows import (combine_imps_wc, kkr_flex_wc,\n",
    "                                 kkr_imp_wc, kkr_imp_sub_wc\n",
    "                                )\n",
    "from aiida_kkr.calculations import KkrCalculation, KkrimpCalculation\n",
    "from aiida.orm import (Group, load_group, load_node, Dict, Code\n",
    "                      )\n",
    "from aiida_kkr.tools import kkrparams\n",
    "from aiida.engine import submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "computational-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One very frequently used option\n",
    "metadata_option_1 = {'max_wallclock_seconds': 36000,'resources': \n",
    "               {'tot_num_mpiprocs': 48, 'num_machines': 1},\n",
    "              'custom_scheduler_commands': \n",
    "              '#SBATCH --account=jara0191\\n\\nulimit -s unlimited; export OMP_STACKSIZE=2g',\n",
    "              'withmpi': True\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suspected-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that here for doped 3d and 4d atoms into the Bi2Te3 host saved in group-74\n",
    "\n",
    "group_74 = load_group(74)\n",
    "## first node of group-74 is for kkr_imp_wc process\n",
    "# is being used for the host_gf or kkr_flex files\n",
    "\n",
    "imp_wc_with_gf = load_node(16100)\n",
    "imp1_wc = group_74.nodes[1]\n",
    "imp2_wc = group_74.nodes[2]\n",
    "\n",
    "# gf_host_remote = imp_wc_with_gf.inputs.remote_data_gf\n",
    "# host_gf_wc = imp_wc_with_gf.get_outgoing(node_class=kkr_flex_wc).all()[0].node\n",
    "\n",
    "\n",
    "impurity1_output_node = imp1_wc.outputs.workflow_info\n",
    "impurity2_output_node = imp2_wc.outputs.workflow_info\n",
    "offset_imp2 = {'index':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitted-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_74 = load_group(91)\n",
    "# node_list = list(group_74.nodes)\n",
    "# i=0\n",
    "# for node in node_list:\n",
    "#     i += 1\n",
    "#     impurity_info = node.inputs.impurity_info.get_dict()\n",
    "#     print(impurity_info)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satellite-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kkr_code_iffslurm = kkrflex@iffslurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "light-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_node = imp1_wc.get_outgoing(node_class=kkr_imp_sub_wc).all()[0].node\n",
    "## kkr_flex_wc\n",
    "host_gf = imp1_wc.inputs.remote_data_gf.get_incoming(node_class=kkr_flex_wc).all()[0].node\n",
    "kkr_calc = host_gf.get_outgoing(node_class=KkrCalculation).all()[0].node\n",
    "kkr_flex_kkr_param = kkr_calc.inputs.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protected-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkr_flex_kkr_param = kkr_calc.inputs.parameters.get_dict()\n",
    "kkr_flex_kkr_param['RCLUSTZ'] *= 1\n",
    "kkr_flex_kkr_param['NSHELD'] = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bright-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kkr_flex_kkr_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gorgeous-poker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of workflow: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "settings = combine_imps_wc.get_wf_defaults()\n",
    "builder = combine_imps_wc.get_builder()\n",
    "settings['jij_run']= True\n",
    "settings['retrieve_kkrflex'] = False\n",
    "settings['mag_init']= False\n",
    "settings['threshold_switch_high_accuracy'] = 1e-2\n",
    "settings['convergence_criterion'] = 1e-7 #convergence_criterion\n",
    "settings['threshold_aggressive_mixing']= 0.02\n",
    "settings['strmix']= 0.01\n",
    "settings['aggrmix'] = 0.05\n",
    "settings['broyden-number'] = 20\n",
    "settings['nsteps'] = 100\n",
    "settings['kkr_runmax'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabulous-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = scf_node.inputs.options.get_dict()\n",
    "options['max_wallclock_seconds'] = 36000*1\n",
    "# options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "textile-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.impurity1_output_node = impurity1_output_node\n",
    "builder.impurity2_output_node = impurity2_output_node\n",
    "builder.offset_imp2 = Dict(dict=offset_imp2)\n",
    "\n",
    "# scf namespace setup\n",
    "builder.scf.kkrimp = scf_node.inputs.kkrimp\n",
    "builder.scf.options = Dict(dict=options)\n",
    "builder.scf.wf_parameters = scf_node.inputs.wf_parameters\n",
    "\n",
    "# host_gf namespace setup\n",
    "builder.host_gf.kkr = host_gf.inputs.kkr\n",
    "builder.host_gf.options = host_gf.inputs.options\n",
    "builder.host_gf.params_kkr_overwrite = Dict(dict=kkr_flex_kkr_param) #host_gf.inputs.wf_parameters\n",
    "\n",
    "builder.wf_parameters_overwrite = Dict(dict=settings)\n",
    "builder.metadata.label = str(imp1_wc.label+ ':' +imp2_wc.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opening-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To submit the builder\n",
    "# combined_imp_submission = submit(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "approved-operations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of workflow: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "# Note that here for doped 3d atoms into the Bi2Te3 host\n",
    "\n",
    "group_74 = load_group(74)\n",
    "## first node of group-64 is for kkr_imp_wc process\n",
    "# is being used for the host_gf or kkr_flex files\n",
    "\n",
    "imp_wc_with_gf = load_node(16100)\n",
    "imp1_wc = group_74.nodes[1]\n",
    "imp2_wc = group_74.nodes[2]\n",
    "\n",
    "scf = imp1_wc\n",
    "\n",
    "host_wf_parameters = Dict(dict={'NSHELD' : 2500})\n",
    "host_kkr = Code().get_from_string('kkr@claix18_init')\n",
    "\n",
    "scf_kkrimp = Code().get_from_string('kkrflex@claix18_init')\n",
    "options = Dict(dict=metadata_option_1)\n",
    "\n",
    "imp1_output_node = imp1_wc.outputs.workflow_info\n",
    "imp2_output_node = imp2_wc.outputs.workflow_info\n",
    "offset_imp2 = {'index':1}\n",
    "\n",
    "settings = combine_imps_wc.get_wf_defaults()\n",
    "settings['jij_run'] = True\n",
    "settings['dos_run'] = False\n",
    "settings['lmdos'] = False\n",
    "settings['strmix'] = 0.01\n",
    "settings['aggrmix'] = 0.01\n",
    "settings['threshold_aggressive_mixing'] = 0.01\n",
    "settings['convergence_criterion'] = 1e-7\n",
    "settings['threshold_switch_high_accuracy'] = 1e-2\n",
    "settings['retrieve_kkrflex'] = False\n",
    "settings['mag_init'] = False\n",
    "settings['mixreduce'] = 0.5\n",
    "settings['nsteps'] = 100\n",
    "settings['kkr_runmax'] = 10\n",
    "settings['broyden-number'] = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combine_imp_builder = combine_imps_wc.get_builder()\n",
    "combine_imp_builder.impurity1_output_node = imp1_output_node\n",
    "combine_imp_builder.impurity2_output_node = imp2_output_node\n",
    "combine_imp_builder.offset_imp2 = Dict(dict=offset_imp2)\n",
    "\n",
    "# scf namespace setup\n",
    "combine_imp_builder.scf.kkrimp = scf_kkrimp\n",
    "combine_imp_builder.scf.options = options\n",
    "combine_imp_builder.scf.wf_parameters = scf.inputs.wf_parameters\n",
    "\n",
    "# combine_imp_builder.gf_host_remote = \n",
    "# host_gf namespace setup\n",
    "combine_imp_builder.host_gf.kkr = host_kkr\n",
    "combine_imp_builder.host_gf.options = options\n",
    "combine_imp_builder.host_gf.params_kkr_overwrite = host_wf_parameters #host_gf.inputs.wf_parameters\n",
    "\n",
    "combine_imp_builder.wf_parameters_overwrite = Dict(dict=settings)\n",
    "combine_imp_builder.metadata.label = str(imp1_wc.label+ ':' +imp2_wc.label)\n",
    "\n",
    "# submission = submit(combine_imp_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "committed-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of workflow: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "## Here trying to work with host Au and other impurity\n",
    "## THe calc is taken from the wasmer\n",
    "imp_Au_group = load_group(85)\n",
    "wc_list = list(imp_Au_group.nodes)\n",
    "\n",
    "\n",
    "imp_wc_1 = wc_list[0]\n",
    "# print('first imp wc : ', imp_wc_1.label)\n",
    "imp_wc_2 = wc_list[1]\n",
    "# print('econd imp wc : ', imp_wc_2.label)\n",
    "# setting the scf and host namespace\n",
    "\n",
    "scf = imp_wc_1\n",
    "host_wf_parameters = Dict(dict={'NSHELD' : 2500,\n",
    "                                'BZDIVIDE': [40, 40, 40],\n",
    "                                'FCM': 20,\n",
    "                                'EMAX': 1.2,\n",
    "                                'EMIN': -0.8,\n",
    "                                'GMAX': 65.0,\n",
    "                                'LMAX': 3,\n",
    "                                'NCHEB': 12,\n",
    "                              \n",
    "                               })\n",
    "\n",
    "host_kkr = Code().get_from_string('kkr@claix18_init')\n",
    "scf_kkrimp = Code().get_from_string('kkrflex@claix18_init')\n",
    "options = Dict(dict=metadata_option_1)\n",
    "\n",
    "imp1_output_node = imp_wc_1.outputs.workflow_info\n",
    "imp2_output_node = imp_wc_2.outputs.workflow_info\n",
    "offset_imp2 = {'index':1}\n",
    "\n",
    "settings = combine_imps_wc.get_wf_defaults()\n",
    "settings['jij_run'] = False\n",
    "settings['dos_run'] = False\n",
    "settings['lmdos'] = False\n",
    "settings['strmix'] = 0.001\n",
    "settings['aggrmix'] = 0.008\n",
    "settings['threshold_aggressive_mixing'] = 0.008\n",
    "settings['convergence_criterion'] = 1e-7\n",
    "settings['threshold_switch_high_accuracy'] = 1e-2\n",
    "settings['retrieve_kkrflex'] = False\n",
    "settings['mag_init'] = False\n",
    "settings['mixreduce'] = 0.5\n",
    "settings['nsteps'] = 100\n",
    "settings['kkr_runmax'] = 10\n",
    "\n",
    "combine_imp_builder = combine_imps_wc.get_builder()\n",
    "combine_imp_builder.impurity1_output_node = imp1_output_node\n",
    "combine_imp_builder.impurity2_output_node = imp2_output_node\n",
    "combine_imp_builder.offset_imp2 = Dict(dict=offset_imp2)\n",
    "\n",
    "# scf namespace setup\n",
    "combine_imp_builder.scf.kkrimp = scf_kkrimp\n",
    "combine_imp_builder.scf.options = options\n",
    "combine_imp_builder.scf.wf_parameters = scf.inputs.wf_parameters\n",
    "\n",
    "# host_gf namespace setup\n",
    "combine_imp_builder.host_gf.kkr = host_kkr\n",
    "combine_imp_builder.host_gf.options = options\n",
    "combine_imp_builder.host_gf.params_kkr_overwrite = host_wf_parameters #host_gf.inputs.wf_parameters\n",
    "\n",
    "combine_imp_builder.wf_parameters_overwrite = Dict(dict=settings)\n",
    "combine_imp_builder.metadata.label = str(imp1_wc.label+ ':' +imp2_wc.label)\n",
    "# submission = submit(combine_imp_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "toxic-marks",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-8d7ac36d7e5a>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-8d7ac36d7e5a>\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    all_resedue_dict{}\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# An attemp to run a bunch of wc of the double impurity from two groups of single impurity wc or \n",
    "# two list of the single impurity wc\n",
    "\n",
    "def submit_double_imp_wc_bunch( si_imp_list_1, si_imp_list_2, kkr_code, kkr_imp_code,\n",
    "                                builder_options,  group_label, group_descr,\n",
    "                                offset_imp2={'index':1}, max_submission=20, setting=None, \n",
    "                                scf_wf_parameter=None, host_gf_wf_parameters=None, \n",
    "                              \n",
    "                              ):\n",
    "    \"\"\"\n",
    "    params: \n",
    "        : Two groups : Two single imp wc groups.\n",
    "        : Two lists : Two single imp wc list.\n",
    "        : Settings Dict : Parameter settings.\n",
    "        : Builder_options Dict : builder_option\n",
    "        : group label str : Create a group by this name if it does not exist in the DB.\n",
    "        : group descr str : Set the created group description either it exists or not, it not a new group\n",
    "                            will be created.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create group or load existing group\n",
    "    group = group_not_exist_create(group_label=group_label, group_descr=group_descr)\n",
    "    \n",
    "#     test_data and prepare for further\n",
    "    if not isinstance(si_imp_list_1, list):\n",
    "        print('The given impurity wc list 1 is not the list type.')\n",
    "\n",
    "    if not isinstance(si_imp_list_2, list):\n",
    "        print('The given impurity wc list 2 is not the list type.')\n",
    "    \n",
    "    all_combination_dict = {}\n",
    "    all_success_dict = {}\n",
    "    all_submission_dict = {}\n",
    "    all_resedue_dict = {}\n",
    "    \n",
    "    tot_wc_num = 0\n",
    "    all_submission_num = 0\n",
    "    all_success_num = 0\n",
    "    all_failed_num = 0\n",
    "    \n",
    "    # Here to create all the possible dict\n",
    "    for i in range(len(si_imp_list_1)):\n",
    "        for j in range(len(si_imp_list_2)):\n",
    "            node_truple = (i, j)\n",
    "            pk_truple = (i.pk, j.pk)\n",
    "            imp1_info = i.inputs.impurity_info.get_dict()\n",
    "            imp2_info = j.inputs.impurity_info.get_dict()\n",
    "            ilayer1 = str(imp1_info.['ilayer_center'])\n",
    "            ilayer2 = str(imp2_info.['ilayer_center'])\n",
    "            \n",
    "            label= i.label.split(':')[0] + ':'+ j.label+':'+ilayer1+':'+ilayer2        \n",
    "            all_combination_dict[tot_wc_num]['node_truple'] = node_truple\n",
    "            all_combination_dict[tot_wc_num]['pk_truple'] = pk_truple\n",
    "            all_combination_dict[tot_wc_num]['label'] = label\n",
    "            tot_wc_num +=1\n",
    "    \n",
    "    all_resedue_dict = all_combination_dict.copy()\n",
    "    \n",
    "    # To create the submission process\n",
    "    for key, val in all_combination_dict.items():\n",
    "        # ------------\n",
    "        imp1_wc_node = all_combination_dict[key]['node_truple'][0]\n",
    "        imp2_wc_node = all_combination_dict[key]['node_truple'][1]\n",
    "        label = all_combination_dict[key]['label']\n",
    "\n",
    "        if all_failed_num == 10: # TODO: add a argumen in the function\n",
    "            break\n",
    "\n",
    "        \n",
    "        if debug: # TODO add the debug in the function arguments\n",
    "            print('imp1_pk for submission', imp1_wc_node.pk)\n",
    "            print('imp2_pk for submission', imp2_wc_node.pk)\n",
    "        #TODO: Check is the wc is in already Group \n",
    "        # if yes 'continue'\n",
    "\n",
    "        if not dry_run: # TODO add the dry run in the function argument\n",
    "            submission = submit_combine_imp(imp1_wc_node, imp2_wc_node, kkr_code, kkr_imp_code, \n",
    "                                        offset_imp2, options, scf_wf_parameter, label, \n",
    "                                        host_gf_wf_parameters, settings)\n",
    "            all_submission_dict[key] = all_combination_dict[key].copy()\n",
    "            \n",
    "        all_submission_num += 1\n",
    "        while(all_submission_num - all_success_num + all_failed_num >= max_submission) or \n",
    "                (tot_wc_num - all_submission_num == 0):\n",
    "                if submission.is_finished = True:\n",
    "                    if submission.exit_statu = 0 : # TODO: Check here is the submission have right variable\n",
    "                        all_success_num +=1\n",
    "                        all_success_dict[key] = all_combination_dict[key].copy()\n",
    "                        all_resedue_dict.pop(key)\n",
    "                        ## TODO: Add in to the group\n",
    "                    else:\n",
    "                        all_failed_num += 1\n",
    "                        if all_failed_num == 10: # TODO: add a argumen in the function\n",
    "                            break\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vanilla-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_combine_imp(imp1_wc_node, imp2_wc_node, kkr_code, kkr_imp_code, offset_imp2, options, \n",
    "                       scf_wf_parameter, label, host_gf_wf_parameters, settings):\n",
    "    \n",
    "    from aiida_kkr.workflows import combine_imps_wc, kkr_imp_sub_wc, kkr_flex_wc\n",
    "\n",
    "    imp1_output = imp1_wc_node.outputs.workflow_info\n",
    "    imp2_output = imp2_wc_node.outputs.workflow_info\n",
    "    if scf_wf_parameter==None:\n",
    "        sub_wc1_node = imp1_wc_node.get_outgoing(node_class=kkr_imp_sub_wc).first().node\n",
    "        scf_wf_parameters = sub_wc1_node.inputs.wf_parameters # TODO : check  'inputs.wf_parameters' is right\n",
    "    if params_kkr_overwrite==None:\n",
    "        sub_gf_write_out = imp1_wc_node.get_outgoing(node_class=kkr_flex_wc).first().node\n",
    "        host_gf_wf_parameters = sub_gf_write_out.inputs.params_kkr_overwrite\n",
    "    if settings==None:\n",
    "        settings = imp1_wc_node.inputs.wf_parameters_overwrite\n",
    "    if label==None:\n",
    "        label = 'pk' + str(imp1_wc_node.pk)+':'+ str(imp1_wc_node.pk)\n",
    "    \n",
    "    builder = combine_imps_wc.get_builder()\n",
    "    builder.impurity1_output_node = imp1_output\n",
    "    builder.impurity2_output_node = imp2_output\n",
    "    builder.offset_imp2 = offset_imp2\n",
    "    \n",
    "    builder.scf.kkrimp = kkr_imp_code\n",
    "    builder.scf.options = options\n",
    "    builder.scf.wf_parameters = scf_wf_parameters\n",
    "    \n",
    "    builder.host_gf.kkr = kkr_code\n",
    "    builder.host_gf.options = options\n",
    "    builder.host_gf.params_kkr_overwrite = host_gf_wf_parameters #host_gf.inputs.wf_parameters\n",
    "    if settings!=None:\n",
    "        builder.wf_parameters_overwrite = settings\n",
    "    builder.metadata.label = label\n",
    "#     submission = submit(builder)\n",
    "    return submission\n",
    "def group_not_exist_create(group_label, group_descr):\n",
    "    from aiida.orm import load_group, Group\n",
    "    \"\"\"\n",
    "        Check the group exist either must create\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "         group = load_group(group_label)\n",
    "    except:\n",
    "        print('Group named {} is not exist but is being created .'.format(group_label))\n",
    "        group = Group(label=group_label, description=group_descr)\n",
    "        group.store()\n",
    "        print('Newly created group pk {}'.format(group.pk))\n",
    "    return group\n",
    "\n",
    "# TODO:\n",
    "# Define a function to check any wc with the similar label is exist in the  work_chain_group\n",
    "# if exist return true\n",
    "def check_wc_exist_in_group(group, wc_labe):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "satellite-morocco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group named None is not exist but is being created .\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Group label must be provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0edb1f4ef1c5>\u001b[0m in \u001b[0;36mgroup_not_exist_create\u001b[0;34m(group_label, group_descr)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m          \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/utils/__init__.py\u001b[0m in \u001b[0;36mload_group\u001b[0;34m(identifier, pk, uuid, label, sub_classes, query_with_dashes)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0maiida\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupEntityLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     return load_entity(\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mGroupEntityLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/utils/__init__.py\u001b[0m in \u001b[0;36mload_entity\u001b[0;34m(entity_loader, identifier, pk, uuid, label, sub_classes, query_with_dashes)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minputs_provided\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"one of the parameters 'identifier', pk', 'uuid' or 'label' has to be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minputs_provided\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: one of the parameters 'identifier', pk', 'uuid' or 'label' has to be specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5512235cb5d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgroup_descr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_not_exist_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_descr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_descr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-0edb1f4ef1c5>\u001b[0m in \u001b[0;36mgroup_not_exist_create\u001b[0;34m(group_label, group_descr)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Group named {} is not exist but is being created .'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_descr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Newly created group pk {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/aiida-core/aiida/orm/groups.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, label, user, description, type_string, backend)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \"\"\"\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Group label must be provided'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_string\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Group label must be provided"
     ]
    }
   ],
   "source": [
    "group_label = 'test_group_delete_this'\n",
    "group_descr = 'Test_group_descr'\n",
    "# group_label.is_stored\n",
    "\n",
    "group_label=None\n",
    "group_descr=None\n",
    "\n",
    "group = group_not_exist_create(group_label=group_label, group_descr=group_descr)\n",
    "group.is_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-communications",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-acceptance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-howard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiiDA",
   "language": "python",
   "name": "aiida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
