{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tender-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile name :  default\n",
      "profile database host name :  localhost\n",
      "default user :  r.mozumder@fz-juelich.de\n"
     ]
    }
   ],
   "source": [
    "#load aiida environment and connect to database\n",
    "from aiida import load_profile\n",
    "from aiida.orm import computers\n",
    "profile = load_profile()\n",
    "print('profile name : ',profile.name)\n",
    "print('profile database host name : ',profile.database_hostname)\n",
    "print('default user : ',profile.default_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classes and functions\n",
    "from aiida.orm import CifData, Code, Dict, load_node, StructureData \n",
    "from aiida.orm import (Group, load_group, load_node, load_code, groups,\n",
    "                      WorkChainNode, QueryBuilder)\n",
    "from aiida.engine import submit\n",
    "from aiida.common.exceptions import NotExistent\n",
    "from aiida_kkr.workflows import kkr_imp_sub_wc, kkr_imp_dos, kkr_imp_wc, kkr_startpot_wc\n",
    "import numpy as np\n",
    "from aiida_kkr.calculations import KkrimpCalculation, VoronoiCalculation\n",
    "import matplotlib.pyplot as plt\n",
    "from aiida_kkr.tools.common_workfunctions import get_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-blend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absolute-suggestion",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-a9017cdca2b9>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-a9017cdca2b9>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    print('No such pk or uuid: {} is present in the database.'format(voro_node))\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Structure data from voronoi calc or kkr_startpot_wc\n",
    "def Struc_from_voro(voro_node, host_structure=True, imp_structure=False):\n",
    "    # Packages and module\n",
    "    from aiida.common.exceptions import InputValidationError\n",
    "    from aiida_kkr.calculations import VoronoiCalculation\n",
    "    from aiida_kkr.workflows import kkr_startpot_wc \n",
    "    from aiida.orm import StructureData, Node\n",
    "    \"\"\"\n",
    "    Structure from the voronoi calcjob or voro_startpot_wc\n",
    "    voro_node: (voro_calc)\n",
    "    \"\"\"\n",
    "    # To check voro_node in node or ID\n",
    "    if not isinstance(voro_node, Node):\n",
    "        try:\n",
    "            voro_node = load_node(voro_node)\n",
    "        except IndentationError:\n",
    "            print('No such pk or uuid: {} is present in the database.'format(voro_node))\n",
    "            \n",
    "    host_struc, imp_host_struc = None, None\n",
    "    \n",
    "    # For voronoi calcjob\n",
    "    if (voro_node.process_class==VoronoiCalculation) :\n",
    "        ## Degug here\n",
    "        print('This Voronoicalculation')\n",
    "        struc = voro_node.inputs.structure\n",
    "        # Check for is it from ancector wc or created there\n",
    "        # For example the struc from sub kkr_startpot_wc in kkr_imp_wc is created there so \n",
    "        # no inconing_node is available \n",
    "        \n",
    "        if struc.get_incoming().first() == []\n",
    "            imp_host_struc = struc\n",
    "    # For kkr_startpot_wc  \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-movie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### NOTE: If this csucessful then please add it into the 'tools_development' ipynb\n",
    "## In this part the nodes from a group , having with different class and kind of nodes, \n",
    "##been collected to store in new group only considering the kkr_imp_wc node\n",
    "\n",
    "group_wasmer = load_group(83)\n",
    "# node_label\n",
    "debug= False\n",
    "wasmer_grp_list = list(group_wasmer.nodes)\n",
    "group_label = 'imp_embedded_Au_by_wasmer'\n",
    "try:\n",
    "    new_grp = load_group(group_label)\n",
    "    new_grp_list = list(new_grp.nodes)\n",
    "    new_grp_list =  [node.pk for node in new_grp_list]\n",
    "    print('Group as named %s is already stored, so no need to create the group'%group_label)\n",
    "except:\n",
    "    new_grp = Group(label=group_label)\n",
    "    new_grp.store()\n",
    "    print(' A new node created as named %s' %node_label)\n",
    "\n",
    "i=0\n",
    "imp_wc_no = 0\n",
    "for index in range(len(wasmer_grp_list)):\n",
    "    node = wasmer_grp_list[index]\n",
    "    if node.node_type.split('.')[-2]=='WorkChainNode':\n",
    "        if (u'kkr_imp_wc' == node.process_label):\n",
    "            imp_wc_no += 1\n",
    "            if node.pk in new_grp_list[:]:\n",
    "                print('node {} is already exist'.format(node.pk))\n",
    "            else:\n",
    "                new_grp.add_nodes(node)\n",
    "#             if debug:\n",
    "#                 print(node.process_label)\n",
    "#                 print('pk: %7d'%node.pk)\n",
    "#                 print(wasmer_grp_list[i])\n",
    "#                 print(node.label)\n",
    "                \n",
    "                        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "common-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to develop to delete the node from database\n",
    "## and at the same time from the remote folder\n",
    "\n",
    "## Add the following possible services\n",
    "# 1. Give the print option for how many decendant node will be \n",
    "#       and take the permission. Add option wether need to take \n",
    "#         permission or not.\n",
    "# 2. Also print how many calcjob node will be deleted under permission \n",
    "# 3. Print'remote directory' to check that all the data from the\n",
    "#     remote dir are deleted or not.\n",
    "## Technique\n",
    "# 1. Use the QuaryDB()\n",
    "# Use the cleandir\n",
    "\n",
    "def del_node(node_pk):\n",
    "    \"\"\"\n",
    "    1. This function will delete the node data from the database and also from the remote_dir\n",
    "    \"\"\"\n",
    "    from aiida.orm import load_node\n",
    "    from aiida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "differential-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section-1\n",
    "### A function to delete the data of calculation output calcjob list (pks) from the remote dir.\n",
    "\n",
    "# later add it with the del_node  function\n",
    "# This is successfully done\n",
    "\n",
    "def delete_remote_workdir(pks, verbosity=0, dry_run= True):\n",
    "    from aiida.common import exceptions\n",
    "    from aiida.orm import load_node\n",
    "    from aiida.orm import computers\n",
    "    import sys\n",
    "    # TODO : add the verbosity as discused here \n",
    "    # https://aiida.readthedocs.io/projects/aiida-core/en/v1.5.0/_modules/aiida/manage/database/delete/nodes.html\n",
    "\n",
    "    \"\"\"\n",
    "    :param pks: calc node list\n",
    "    :param verbosity: 0 prints nothing\n",
    "                      1 prints just sums and total\n",
    "                      2 prints indivisual nodes\n",
    "    :param dry_run: Do not delete anything just show the status as in the verbosity given\n",
    "    \"\"\"\n",
    "    removed_path_list = [] # The part of the path will be deleted\n",
    "    remote_path_list = []  # The original path\n",
    "    updated_path_list = [] # After removing the part of the path\n",
    "    loadable_list = [] # To load the node and save it loadable_list\n",
    "\n",
    "    # To check the loadable calcjob list\n",
    "    for pk in pks:\n",
    "        try:\n",
    "            load_node(pk)\n",
    "        except exceptions.NotExistent:\n",
    "            print('calcjob {} can not be retrieved'.format(pk))\n",
    "#             sys.exit()\n",
    "        else:\n",
    "            loadable_list.append(pk)\n",
    "    # Computer data\n",
    "    \n",
    "   \n",
    "    for pk in loadable_list:\n",
    "        load_pk = load_node(pk)\n",
    "        # computer data\n",
    "        computer = load_pk.computer\n",
    "        computer_name = computer.label\n",
    "        print(computer_name)\n",
    "        \n",
    "        remote_path = load_pk.get_remote_workdir()\n",
    "        remote_path_list.append(remote_path)\n",
    "        \n",
    "        delete_folder = remote_path.split('/')[-1]\n",
    "        removed_path_list.append(delete_folder)\n",
    "\n",
    "        new_remote_path = remote_path.replace(remote_path.split('/')[-1], '')\n",
    "        updated_path_list.append(new_remote_path)\n",
    "        \n",
    "        \n",
    "        if not dry_run:\n",
    "            # Open the connection to the remote folder/dir via transport\n",
    "            computer_transport = computer.get_transport()\n",
    "            is_transport_open = computer_transport.is_open\n",
    "            if not is_transport_open:\n",
    "                computer_transport.open()\n",
    "            try:\n",
    "                computer_transport.rmtree(remote_path)\n",
    "            except IOError as ex:\n",
    "                print(ex)\n",
    "        elif dry_run:\n",
    "            \n",
    "            for i, paths in enumerate(zip(remote_path_list, updated_path_list)):\n",
    "                print('Before the delation the original path list : {}\\n'.format(paths[1]))\n",
    "                print('After deletion the modefied or updated path : {}'.format(paths[0]))\n",
    "\n",
    "# please note that it is tested for one calc list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alpha-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calcjob 203855 can not be retrieved\n",
      "calcjob 654566 can not be retrieved\n"
     ]
    }
   ],
   "source": [
    "delete_remote_workdir([203855,654566], dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "20046 = ck142666/aiida/computers/claix18_init/33/72/09bd-3958-401f-83f2-1fdbe3411e74\n",
    "20024 = ck142666/aiida/computers/claix18_init/17/10/feef-b826-453e-a5d8-58b8d1dd08ff\n",
    "20010 = ck142666/aiida/computers/claix18_init/5e/f7/5c5f-0355-446d-94c5-4466340e8817\n",
    "19995 = ck142666/aiida/computers/claix18_init/b5/e3/6d58-837a-454c-8c9c-d380454a4409\n",
    "19972 = ck142666/aiida/computers/claix18_init/f2/33/0597-face-495e-be74-b321c7ee6689\n",
    "19967 = ck142666/aiida/computers/claix18_init/5f/f0/b136-ccfe-4f81-b246-65cbfcbf42c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exciting-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "#section-2\n",
    "## This code  will help to workchain as explained in the filter\n",
    "qb = QueryBuilder()\n",
    "ll = list(qb.append([WorkChainNode],\n",
    "                    filters={\n",
    "                        'and':[\n",
    "                            {'attributes.process_label':'combine_imps_wc'},\n",
    "                            {'or':[\n",
    "                                {'attributes.process_status': 'excepted'},\n",
    "                                {'attributes.exit_status':{'!in':[0]}}\n",
    "                                 ]\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                   \n",
    "                   \n",
    "                   ).all())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exceptional-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#section-3\n",
    "## To check any specific pk in the pk_list exist or not\n",
    "def check_pk_exist(pk_list, pk):\n",
    "    for i in pk:\n",
    "        for j in pk_list:\n",
    "            if(i==j):\n",
    "                print('pk-{} is exist in pk_list'.format(i))\n",
    "                continue\n",
    "\n",
    "len(ll)\n",
    "\n",
    "pk_list = [i[0].pk for i in ll]\n",
    "pk_list.sort()\n",
    "check_pk_exist(pk_list,[22232])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "geographic-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It returns all the calcjob from a WC node\n",
    "def find_calcJob(pk_or_node, debug=False):\n",
    "    \n",
    "    calcjob_node_list=[]\n",
    "    wc_node_list = []\n",
    "    if isinstance( pk_or_node, int):\n",
    "        if debug:\n",
    "            print('This is pk')\n",
    "        node = load_node(pk_or_node)\n",
    "    else:\n",
    "        if debug:\n",
    "            print('This is node.')\n",
    "        node= pk_or_node\n",
    "        \n",
    "    ## Use the get_calcjob_wc to get descendent calcjob list and  wc list\n",
    "    calc_list, wc_list = get_calcjob_wc(node)\n",
    "    calcjob_node_list += calc_list\n",
    "    \n",
    "    while len(wc_list)!=0:\n",
    "        new_wc_list = []\n",
    "\n",
    "        for i in wc_list[:]:\n",
    "            calc_list, wc_list = get_calcjob_wc(i)\n",
    "            new_wc_list += wc_list\n",
    "            calcjob_node_list += calc_list\n",
    "            \n",
    "        wc_list = new_wc_list\n",
    "\n",
    "    return calcjob_node_list\n",
    "\n",
    "## This function returns calcjob_list and wc_list from a wc or calcjob node   \n",
    "def get_calcjob_wc(node):\n",
    "    \"\"\"\n",
    "    :param: node\n",
    "    :return: workchain node list and calcjob node list\n",
    "    \"\"\" \n",
    "    from aiida.orm import CalcJobNode, WorkChainNode\n",
    "    wc = []\n",
    "    calc_job = []\n",
    "    \n",
    "    if node.node_type == 'process.workflow.workchain.WorkChainNode.':\n",
    "        \n",
    "    # here all outgoing worchain node\n",
    "        out_going_wc = node.get_outgoing(node_class=WorkChainNode).all()\n",
    "        wc = [i.node for i in out_going_wc[:]]\n",
    "        \n",
    "    # here all outgoing calcjob node\n",
    "        out_going_calc = node.get_outgoing(node_class=CalcJobNode).all()\n",
    "        calc_job = [i.node for i in out_going_calc[:]]\n",
    "                    \n",
    "    elif node.node_type == 'process.calculation.calcjob.CalcJobNode.':\n",
    "        calc_job.append(node)\n",
    "    \n",
    "    return calc_job, wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-legislation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-hollow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiiDA",
   "language": "python",
   "name": "aiida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
