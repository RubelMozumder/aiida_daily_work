{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surrounded-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the aiida profile\n",
    "from aiida import load_profile\n",
    "aiida_profile = load_profile()\n",
    "aiida_profile.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INFO:: In this class all the tools for bunch of wc submission have been created \n",
    "\n",
    "class DataUtils:\n",
    "\n",
    "## SECTION1-1 : In this section to delete the remote workdir for calcjob and  nodes from the DB     \n",
    "    # please note that it is tested for one calc list\n",
    "    def delete_remote_workdir(self, pks: list, verbosity=0, dry_run= True):\n",
    "        from aiida.common import exceptions\n",
    "        from aiida.orm import load_node\n",
    "        from aiida.orm import computers\n",
    "        import sys\n",
    "        # TODO : add the verbosity as discused here \n",
    "        # https://aiida.readthedocs.io/projects/aiida-core/en/v1.5.0/_modules/aiida/manage/database/delete/nodes.html\n",
    "\n",
    "        \"\"\"\n",
    "        :param pks: calc node list\n",
    "\n",
    "        \"\"\"\n",
    "        removed_path_list = [] # The part of the path will be deleted\n",
    "        remote_path_list = []  # The original path\n",
    "        updated_path_list = [] # After removing the part of the path\n",
    "        loadable_list = [] # To load the node and save it loadable_list\n",
    "        loaded_node_list = []\n",
    "        # To check the loadable calcjob list\n",
    "        for pk in pks:\n",
    "            try:\n",
    "                loaded_node = load_node(pk)\n",
    "            except exceptions.NotExistent:\n",
    "                print('This is calcjob node'.format(pk))\n",
    "                loaded_node = pk\n",
    "                loaded_node_list.append(loaded_node)\n",
    "                #             sys.exit()\n",
    "            else:\n",
    "                loaded_node_list.append(loaded_node)\n",
    "        # Computer data\n",
    "\n",
    "        for node in loaded_node_list:\n",
    "            load_pk = node\n",
    "            # computer data\n",
    "            computer = load_pk.computer\n",
    "            computer_name = computer.label\n",
    "            print(computer_name)\n",
    "\n",
    "            remote_path = load_pk.get_remote_workdir()\n",
    "            remote_path_list.append(remote_path)\n",
    "\n",
    "            delete_folder = remote_path.split('/')[-1]\n",
    "            removed_path_list.append(delete_folder)\n",
    "\n",
    "            new_remote_path = remote_path.replace(remote_path.split('/')[-1], '')\n",
    "            updated_path_list.append(new_remote_path)\n",
    "\n",
    "        if dry_run or verbosity == 3:\n",
    "\n",
    "            for i, paths in enumerate(zip(remote_path_list, updated_path_list)):\n",
    "                print('Before the delation the original path list : {}\\n'.format(paths[0]))\n",
    "                print('After deletion the modefied or updated path : {}'.format(paths[1]))\n",
    "        if verbosity == 3 or verbosity == 2:\n",
    "            val = input(\"Are you agree to clean the remote workdir (y/n) : \")\n",
    "        else:\n",
    "            val = 'y'\n",
    "        if str(val)=='y' or str(val)=='Y':\n",
    "            if not dry_run:\n",
    "                for remote_path in remote_path_list:\n",
    "\n",
    "                        # Open the connection to the remote folder/dir via transport\n",
    "                        computer_transport = computer.get_transport()\n",
    "                        is_transport_open = computer_transport.is_open\n",
    "                        if not is_transport_open:\n",
    "                            computer_transport.open()\n",
    "                        try:\n",
    "                            computer_transport.rmtree(remote_path)\n",
    "                        except IOError as ex:\n",
    "                            print(ex)\n",
    "        else:\n",
    "            print('Nothing to clean from the remote workdir!')\n",
    "    ## It returns all the calcjob from a WC node\n",
    "    def find_calcJob(self, pk_or_node, debug=True):\n",
    "\n",
    "        calcjob_node_list=[]\n",
    "        wc_node_list = []\n",
    "        try:\n",
    "            if isinstance( pk_or_node, int):\n",
    "                if debug:\n",
    "                    print('This is pk')\n",
    "                node = load_node(pk_or_node)\n",
    "            else:\n",
    "                if debug:\n",
    "                    print('This is node.')\n",
    "                node= pk_or_node\n",
    "        except:\n",
    "            print('{} is nither node ID nor aiida_node. '.format(pk_or_node))\n",
    "\n",
    "        ## Use the get_calcjob_wc to get descendent calcjob list and  wc list\n",
    "        calc_list, wc_list = get_calcjob_wc(node)\n",
    "        calcjob_node_list += calc_list\n",
    "\n",
    "        while len(wc_list)!=0:\n",
    "            new_wc_list = []\n",
    "\n",
    "            for i in wc_list[:]:\n",
    "                calc_list, wc_list = get_calcjob_wc(i)\n",
    "                new_wc_list += wc_list\n",
    "                calcjob_node_list += calc_list\n",
    "\n",
    "            wc_list = new_wc_list\n",
    "\n",
    "        return calcjob_node_list\n",
    "\n",
    "    ## This function returns calcjob_list and wc_list from a wc or calcjob node   \n",
    "    def get_calcjob_wc(self, node):\n",
    "        \"\"\"\n",
    "        :param: node\n",
    "        :return: workchain node list and calcjob node list\n",
    "        \"\"\" \n",
    "        from aiida.orm import CalcJobNode, WorkChainNode\n",
    "        wc = []\n",
    "        calc_job = []\n",
    "\n",
    "        if node.node_type == 'process.workflow.workchain.WorkChainNode.':\n",
    "\n",
    "        # here all outgoing worchain node\n",
    "            out_going_wc = node.get_outgoing(node_class=WorkChainNode).all()\n",
    "            wc = [i.node for i in out_going_wc[:]]\n",
    "\n",
    "        # here all outgoing calcjob node\n",
    "            out_going_calc = node.get_outgoing(node_class=CalcJobNode).all()\n",
    "            calc_job = [i.node for i in out_going_calc[:]]\n",
    "\n",
    "        elif node.node_type == 'process.calculation.calcjob.CalcJobNode.':\n",
    "            calc_job.append(node)\n",
    "\n",
    "        return calc_job, wc\n",
    "    \n",
    "    # This is the final del_node_function. Using this function for any specific wc node the node from the \n",
    "    # Db as well as the calcjob data from the remote workdir can be deleted.\n",
    "    def del_node(self, node_pks, dry_run=True, verbosity=3, debug=True, only_remote_dir=False,\n",
    "                only_database=False):\n",
    "        \"\"\"\n",
    "        1. This function will delete the node data from the database and also from the remote_dir\n",
    "\n",
    "        :params node_pks: (list) list of workchain to delete from database as well as from remote workdir\n",
    "        :param verbosity: 0 prints nothing.  This is for workdir and wc\n",
    "                          1 prints just sums and total.   This is for workdir but not for wc\n",
    "                          2 prints indivisual nodes.  This is for workdir and wc\n",
    "        :param dry_run: Do not delete anything just show the status as in the verbosity given\n",
    "        \"\"\"\n",
    "        from aiida.orm import load_node\n",
    "        from aiida.manage.database.delete.nodes import delete_nodes\n",
    "\n",
    "        calcjobs_list = []\n",
    "        pks_given = []\n",
    "        for i in node_pks:    \n",
    "            try:\n",
    "                if isinstance( i, int):\n",
    "                    if debug:\n",
    "                        print('This might be pk or uiid')\n",
    "                    node = load_node(i)\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print('This might be a node.')\n",
    "                    node= i\n",
    "            except:\n",
    "                print('{} is nither node ID nor aiida_node. '.format(i))\n",
    "\n",
    "            pks_given.append(node.pk)\n",
    "\n",
    "            calcjobs = find_calcJob(node, debug)\n",
    "            calcjobs_list += calcjobs\n",
    "            print('calcjob list : ', calcjobs_list,)\n",
    "        if only_remote_dir:\n",
    "            delete_remote_workdir(calcjobs_list, verbosity=verbosity, dry_run=dry_run)\n",
    "        if only_database:\n",
    "            delete_nodes(pks_given, verbosity=verbosity, dry_run=dry_run,force=False)\n",
    "\n",
    "## SECTION-1: Ends here\n",
    "\n",
    "## SECTION-2: In this section group creation, check wc in group, save wc in group\n",
    "\n",
    "    def group_not_exist_create(self, group_label, group_descr=None):\n",
    "        from aiida.orm import load_group, Group\n",
    "        \"\"\"\n",
    "            Check the group exist either must create\n",
    "        \"\"\"\n",
    "        if group_descr==None:\n",
    "            group_descr='No Description is added'\n",
    "\n",
    "        try:\n",
    "             group = load_group(group_label)\n",
    "        except:\n",
    "            print('Group named {} is not exist but is being created .'.format(group_label))\n",
    "            group = Group(label=group_label, description=group_descr)\n",
    "            group.store()\n",
    "            print('Newly created group pk : {}'.format(group.pk))\n",
    "        return group\n",
    "\n",
    "\n",
    "    def check_wc_exist_in_group(self, group, wc_label=None, wc_pk=None, wc_node= None):\n",
    "        if not isinstance(group, Group):\n",
    "            try:\n",
    "                group= load_group(group)\n",
    "            except:\n",
    "                return(f'Exception ocours while loading group ID {group}')\n",
    "            \n",
    "        nodes_list = list(group.nodes)\n",
    "        nodes_label = [i.label for i in nodes_list[:]]\n",
    "        nodes_pk = [i.pk for i in nodes_list[:]]\n",
    "\n",
    "        if wc_label in nodes_label:\n",
    "            print('node_label : {} is exist in the group : {}.'.format(wc_label, group.label))\n",
    "            return True\n",
    "\n",
    "        elif wc_pk in nodes_pk:\n",
    "            print('node_pk-{} is exist in the group-{}.'.format(wc_pk, group.label))\n",
    "            return True\n",
    "        \n",
    "        elif wc_node in nodes_list:\n",
    "            print('node-{} is exist in the group-{}.'.format(wc_node, group.label))\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def create_group_save_wcs(self,group_label: str=\"\", group_descr: str=\"\", verbose: bool=False,\n",
    "            wc_list: list = [], wc_dict: dict = {}, debug: bool = True\n",
    "                            ) -> Group :\n",
    "        from aiida.orm import load_group, load_node, Node\n",
    "        \" A new group named as <group_label> wil be created if not exist is db and wc from <wc_list> or <wc_dict> will be store.\n",
    "          wc_list: consists pk\n",
    "          wc_dict: consists keys node pk, label, description\n",
    "          Return the actual group\n",
    "        \"\n",
    "\n",
    "\n",
    "        group = self.group_not_exist_create(group_label=group_label, group_descr=group_descr)\n",
    "        members_list = group.nodes\n",
    "        members_label = [i.label for i in nodes_list[:]]\n",
    "        members_pk = [i.pk for i in nodes_list[:]]\n",
    "        \n",
    "        if wc_list != []:\n",
    "            for ID in wc_list[:]:\n",
    "                if isinstance(ID, Node):\n",
    "                    node = ID\n",
    "                else:\n",
    "                    try:\n",
    "                        node = load_node(ID)\n",
    "                    except:\n",
    "                        print(f'This is not node neither identifire given as {ID})\n",
    "                if node.label not in members_label:\n",
    "                    if node.pk not in members_pk:\n",
    "                        group.add_nodes(ID)\n",
    "                else:\n",
    "                    val = input(f\"Node-{ID} is already exist in group-{group.pk}. Do you want to store this node in the mentioned group? (Y/N)\")\n",
    "                    if val == 'y' or val == 'Y':\n",
    "                        group.add_nodes(ID)\n",
    "\n",
    "        elif wc_dict != {}:\n",
    "            for i in wc_dict.keys():\n",
    "                node = load_node(wc_dict[i]['pk'])\n",
    "                if node.label not in members_label:\n",
    "                    if node.pk not in members_pk:\n",
    "                        group.add_nodes(node)\n",
    "                else:\n",
    "                    val = input(f\"Node-{node} is already exist in group-{group.pk}. Do you want to store this node in the mentioned group? (Y/N)\")\n",
    "                    if val == 'y' or val == 'Y':\n",
    "                        group.add_nodes(ID)\n",
    "\n",
    "        return group\n",
    "\n",
    "\n",
    "## SECTION-2: Ends here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_submit:\n",
    "    from aiida.engine import submit\n",
    "## SECTION-1 : In this secction combine imp\n",
    "    ## In this method  combine imp from two preconverged single imp_wc.\n",
    "    def submit_combine_imp(self, imp1_wc_node, imp2_wc_node,  offset_imp2, kkr_code=None, kkr_imp_code= None, \n",
    "                           settings= None, dry_run= True, label= None, gf_host_remote=None, options= None, \n",
    "                           scf_wf_parameters = None, params_kkr_overwrite=None):\n",
    "        \n",
    "        from aiida_kkr.workflows import combine_imps_wc, kkr_imp_sub_wc, kkr_flex_wc\n",
    "        from aiida.orm import Dict\n",
    "        imp1_output = imp1_wc_node.outputs.workflow_info\n",
    "        imp2_output = imp2_wc_node.outputs.workflow_info\n",
    "        \n",
    "        if scf_wf_parameters==None:\n",
    "            sub_wc1_node = imp1_wc_node.get_outgoing(node_class=kkr_imp_sub_wc).first().node\n",
    "            scf_wf_parameters = sub_wc1_node.inputs.wf_parameters\n",
    "        \n",
    "        if gf_host_remote != None:\n",
    "            if params_kkr_overwrite==None:\n",
    "                sub_gf_write_out = imp1_wc_node.get_outgoing(node_class=kkr_flex_wc).first().node\n",
    "                params_kkr_overwrite = sub_gf_write_out.inputs.params_kkr_overwrite\n",
    "        if settings==None:\n",
    "            settings = imp1_wc_node.inputs.wf_parameters_overwrite\n",
    "        if label==None:\n",
    "            label = 'pk' + str(imp1_wc_node.pk)+':'+ str(imp1_wc_node.pk)\n",
    "        \n",
    "        if kkr_code == None:\n",
    "            kkr_code= imp1_wc_node.inputs.kkr\n",
    "        if kkr_imp_code == None:\n",
    "            kkr_imp_code=  imp1_wc_node.inputs.kkrimp\n",
    "        if options == None:\n",
    "            options = imp1_wc_node.inputs.options       \n",
    "\n",
    "        builder = combine_imps_wc.get_builder()\n",
    "        builder.impurity1_output_node = imp1_output\n",
    "        builder.impurity2_output_node = imp2_output\n",
    "        if isinstance(offset_imp2, dict):\n",
    "            builder.offset_imp2 = Dict(dict=offset_imp2)\n",
    "        else:\n",
    "            builder.offset_imp2 = offset_imp2\n",
    "\n",
    "        builder.scf.kkrimp = kkr_imp_code\n",
    "        builder.scf.options = options\n",
    "        builder.scf.wf_parameters = scf_wf_parameters\n",
    "\n",
    "        if gf_host_remote==None:\n",
    "            builder.host_gf.kkr = kkr_code\n",
    "            builder.host_gf.options = options\n",
    "            builder.host_gf.params_kkr_overwrite = params_kkr_overwrite #host_gf.inputs.wf_parameters\n",
    "        else:\n",
    "            builder.gf_host_remote = gf_host_remote\n",
    "        if settings!=None:\n",
    "            if isinstance(settings, dict):\n",
    "                builder.wf_parameters_overwrite = Dict(dict=settings)\n",
    "            else:\n",
    "                builder.wf_parameters_overwrite = settings\n",
    "\n",
    "        builder.metadata.label = label\n",
    "        if not dry_run:\n",
    "            submission = submit(builder)\n",
    "            return submission\n",
    "        else:\n",
    "            msg = ' This is dry_run. '\n",
    "            return msg\n",
    "\n",
    "\n",
    "## SECTION-1 : Ends here\n",
    "\n",
    "## SECTION-2 : In this section single imp dos will be prepared\n",
    "    ##  dos wc from the pre converged kkr_imp_wc\n",
    "    def single_imp_dos_from_scf(self, preconverged_kkr_imp_node, kkr= None, kkrimp= None, options=None,\n",
    "                                wf_parameters=None, host_remote= None, gf_dos_remote= None, kkrimp_remote=None,\n",
    "                                imp_pot_sfd= None, impurity_info= None, params_kkr_overwrite= None,\n",
    "                                dry_run= True\n",
    "                               ):\n",
    "        \n",
    "        from aiida_kkr.workflows import kkr_imp_dos_wc\n",
    "        builder= kkr_imp_dos_wc.get_builder()\n",
    "        if kkr == None:\n",
    "            builder.kkr= preconverged_kkr_imp_node.inputs.kkr\n",
    "        if kkrimp == None:\n",
    "            builder.kkrimp= preconverged_kkr_imp_node.inputs.kkrimp\n",
    "        if options == None:\n",
    "            builder.options= preconverged_kkr_imp_node.inputs.options\n",
    "        if wf_parameters != None:\n",
    "            builder.wf_parameters= wf_parameters\n",
    "        if host_remote != None:\n",
    "            builder.host_remote = host_remote\n",
    "        if gf_dos_remote != None:\n",
    "            builder.gf_dos_remote = gf_dos_remote\n",
    "        if kkrimp_remote != None:\n",
    "            builder.kkrimp_remote = kkrimp_remote\n",
    "        if imp_pot_sfd != None:\n",
    "            builder.imp_pot_sfd = imp_pot_sfd\n",
    "        if impurity_info != None:\n",
    "            builder.impurity_info = impurity_info\n",
    "        if params_kkr_overwrite != None:\n",
    "            builder.params_kkr_overwrite != params_kkr_overwrite\n",
    "        if dry_run:\n",
    "            return(f'This is dryrun for single_imp_dos_from_scf()')\n",
    "        elif not dry_run:\n",
    "            submission = submit(builder)\n",
    "    \n",
    "    \n",
    "    def single_imp_dos_restart(self, pre_kkr_imp_dos, wf_parameters, params_kkr_overwrite= None dry_run = True):\n",
    "        \n",
    "        from aiida.engine import submit\n",
    "        builder= pre_kkr_imp_dos.get_builder_restart()\n",
    "        builder.wf_parameters= wf_parameters\n",
    "        builder.params_kkr_overwrite = params_kkr_overwrite\n",
    "        if dry_run:\n",
    "            return(f'This is dry run for single_imp_dos_restart')\n",
    "        elif not dry_run:\n",
    "            submission = submit(builder)\n",
    "            return submission\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "## SECTION-2 : Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bunch_wc:\n",
    "    \"\"\"\n",
    "        In this section bunch of wc will be submitted.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.Max_fail = 3\n",
    "        self.Max_submit = 30\n",
    "        self.Is_sumit_finished = False\n",
    "from aiida.orm import Code, Dict, RemoteData\n",
    "from typing import Union\n",
    "## --------------------------------------------\n",
    "## SECTION-1: This is the part for prepareing of bunch of calculation\n",
    "# and this part will consist also dict of bunch\n",
    "    @classmethod\n",
    "    def combine_imps_bunch_settings(cls, si_imp_list1: list, si_imp_list2: list, kkr_code: Code= None, kkr_imp_code: Code=None,\n",
    "                          builder_options: Dict = None, succ_group_label: str: None, succ_group_descr: str = None,\n",
    "                          offset_imp2:Union[dict, Dict] = {'index':1}, max_submission: int=30, settings: Union[dict, Dict] =None,\n",
    "                          gf_host_remote: RemoteData= None, scf_wf_parameters: Union[dict, Dict]=None, debug: bool= False,\n",
    "                          params_kkr_overwrite: Union[dict,Dict]= None, dry_run: bool= True, max_fail_wc: int= 3\n",
    "                          ):\n",
    "        \"\n",
    "            In this method set all the inputs as function parameters from the user.\n",
    "        \"\n",
    "\n",
    "        #TODO: Change all the si_imp_list1 into si_imp1_list\n",
    "        #TODO: \n",
    "        from Bunch_wc_submission_package.submission_utils import submission_utils as su\n",
    "        self = cls()\n",
    "        self.Si_imp1_list= si_imp_list1\n",
    "        self.Si_imp2_list= si_imp_list2\n",
    "        self.Kkr_code = kkr_code\n",
    "        self.Kkr_imp_code = Kkr_imp_code\n",
    "        self.Options = builder_options\n",
    "\n",
    "        # TODO: Think about codes kkr, kkr_imp, builder_options\n",
    "        if succ_group_label == None:\n",
    "            self.Succ_group_label= 'No_group_label_is_found'\n",
    "        else:\n",
    "            self.Succ_group_label= succ_group_label\n",
    "\n",
    "        if succ_group_descr == None:\n",
    "            self.Succ_group_desc= 'No_group_description_is_found'\n",
    "        else:\n",
    "            self.Succ_group_desc= succ_group_descr\n",
    "\n",
    "        if fail_group_label == None:\n",
    "            self.Fail_group_label= 'No_group_label_is_found_failed'\n",
    "        else:\n",
    "            self.Fail_group_label= str(succ_group_label) + '_failed'\n",
    "\n",
    "        if fail_group_descr == None:\n",
    "            self.Fail_group_desc= 'No_group_description_is_found_failed'\n",
    "        else:\n",
    "            self.Fail_group_desc= str(succ_group_descr) + '_failed'\n",
    "\n",
    "\n",
    "        if isinstance(offset_imp2, dict):\n",
    "            self.Offset_imp2= Dict(dict=offset_imp2)\n",
    "        else:\n",
    "            self.Offset_imp2= offset_imp2\n",
    "\n",
    "        self.Max_submit= max_submission\n",
    "\n",
    "        if isinstance(settings, dict):\n",
    "            self.Settings = Dict(dict=settings)\n",
    "        else:\n",
    "            self.Settings = settings\n",
    "\n",
    "        # TODO: If remote host gf is no given after the first the calc take it as from the first. Employ it later\n",
    "        self.Gf_host_remote= gf_host_remote\n",
    "\n",
    "        if isinstance(scf_wf_parameters, dict):\n",
    "            self.Scf_wf_parameters= Dict(dict= scf_wf_parameters)\n",
    "        else:\n",
    "            self.Scf_wf_parameters= scf_wf_parameters\n",
    "\n",
    "        self.Debug = debug\n",
    "\n",
    "        if isinstance(params_kkr_overwrite, dict):\n",
    "            self.Params_kkr_overwrite= Dict(dict=params_kkr_overwrite)\n",
    "        else:\n",
    "            self.Params_kkr_overwrite = params_kkr_overwrite\n",
    "\n",
    "        self.Dry_run= dry_run\n",
    "\n",
    "        self.Max_fail= max_fail_wc\n",
    "        self.Si_submit = su.submit_combine_imp #The submit function\n",
    "\n",
    "        self.All_combination_dict = su.create_combine_imps_combination(self.Si_imp1_list, self.Si_imp2_list)\n",
    "        return self\n",
    "    \n",
    "    def create_combine_imps_combination(self, imp_list1: list, imp_list2: list)-> dict :\n",
    "        \"\n",
    "            imp1_list1; imp2_list2 are the wc node lists.\n",
    "            Create all possible combinations from two given lists.\n",
    "            Returns dict consists of dict <wc_num> consist of <label>, and empty <submission node>. \n",
    "            The label for each combine_imps_wc is also create here.\n",
    "        \"\n",
    "        if not isinstance(si_imp_list1, list):\n",
    "            print('The given impurity wc list 1 is not the list type.')\n",
    "            return print('Please provide single_imp1_list.')\n",
    "        if not isinstance(si_imp_list2, list):\n",
    "            print('The given impurity wc list 2 is not the list type.')\n",
    "            return print('Please provide single_imp2_list.')\n",
    "\n",
    "        for i in si_imp_list1[:]:\n",
    "            for j in si_imp_list2[:]:\n",
    "                node_truple = (i, j)\n",
    "                pk_truple = (i.pk, j.pk)\n",
    "                imp1_info = i.inputs.impurity_info.get_dict()\n",
    "                imp2_info = j.inputs.impurity_info.get_dict()\n",
    "                ilayer1 = str(imp1_info['ilayer_center'])\n",
    "                ilayer2 = str(imp2_info['ilayer_center'])\n",
    "                try:\n",
    "                    label= i.label.split(':')[0] + ':'+ j.label+'_il_'+ilayer1+'_il_'+ilayer2\n",
    "                else:\n",
    "                    #print(f\"INFO: Single_imp_wc does not have any label \")\n",
    "                    label = f\"pk:{i.pk}:{j.pk}\"\n",
    "\n",
    "                all_combination_dict[tot_wc_num] = {'label' : label,\n",
    "                                                    'submission': None}\n",
    "        return all_combination_dict\n",
    "\n",
    "\n",
    "    \n",
    "## SECTIION-\"\": In this section general submit will be preapared to submit any of the bunch wc with \n",
    "    # coresponding dict of bunch\n",
    "\n",
    "    def Submit(self):\n",
    "\n",
    "        from Bunch_wc_submission_package.submission_utils import submission_utils as su\n",
    "\n",
    "        # TODO: maybe 'part_1' can be added with the for loop summittion \n",
    "        ## Call required tools from the submission utils\n",
    "        all_combination_dict = self.All_combination_dict.copy()\n",
    "        all_resedue_dict = all_combination_dict.copy()# resedu dict for all the failed dict\n",
    "        all_success_dict = {}\n",
    "        all_submission_dict = {} #TODO change the all_submission dict as all running dict \n",
    "        all_failed_dict = {}\n",
    "        ## some integer variables to track the numbers\n",
    "        tot_wc_num = len(all_combination_dict)\n",
    "        all_submission_num = 0\n",
    "        all_success_num = 0\n",
    "        all_failed_num = 0\n",
    "        ## part_1---\n",
    "\n",
    "        succ_group = su.group_not_exist_create(label = self.Succ_group_label, description= self.Succ_group_descr)\n",
    "        fail_group = su.group_not_exist_create(label = self.Fail_group_label, description= self.Fail_group_descr)\n",
    "\n",
    "        for key, val in all_combination_dict.items():\n",
    "\n",
    "            label = all_combination_dict[key]['label']\n",
    "\n",
    "            wc_pre_exist = su.wc_lbl_in_group(group=succ_group, node_label=label)\n",
    "            if wc_pre_exist:\n",
    "                print('Already one wc named as {} is exist in this group'.format(label))\n",
    "                continue\n",
    "         # TODO: In the docs add the keys in the all_combination_dict[dict_label]'submission' key as empty and 'label' key for each ubmited wc also mention that key in all_combination_dict[key] is for labeling and tracking all the combine dict\n",
    "            submission = su.submit_combine_imp(key_value = val, obj=self)\n",
    "            print(f\"THe submitted combine Imps is : {submission.pk}\")\n",
    "            all_submission_dict[key] = all_combination_dict[key].copy()\n",
    "            all_submission_dict[key]['submission'] = submission\n",
    "            all_submission_num += 1\n",
    "            while((all_submission_num - all_success_num - all_failed_num >= max_submission) or\n",
    "                    (tot_wc_num - all_submission_num == 0) or (all_failed_num == max_fail_wc)):\n",
    "                    t.sleep(60*2)\n",
    "\n",
    "    #       --------------------------------------------------------------------------------\n",
    "                    pop_list = []\n",
    "                    for submit_key in all_submission_dict.keys():\n",
    "                        submission = all_submission_dict[submit_key]['submission']\n",
    "                        if submission.is_finished == True:\n",
    "                            if submission.exit_status == 0 :\n",
    "                                all_success_num +=1\n",
    "                                if all_success_num%5==0:\n",
    "                                    print('all_success_num : ', all_success_num)\n",
    "                                all_success_dict[submit_key] = all_combination_dict[submit_key].copy()\n",
    "                                all_resedue_dict.pop(submit_key)\n",
    "\n",
    "                                succ_group.add_nodes(submission)\n",
    "                                pop_list.append(submit_key)\n",
    "                                su.del_node(node_pks=[submission.pk], dry_run=False, verbosity=0, debug=False, only_remote_dir=True)\n",
    "                            else:\n",
    "                                all_failed_num += 1\n",
    "                                all_failed_dict[submit_key] = all_combination_dict[submit_key].copy()\n",
    "\n",
    "                                print('INFO: all_failed_num : ', all_failed_num)\n",
    "                                fail_group.add_nodes(submission)\n",
    "                                pop_list.append(submit_key)\n",
    "\n",
    "                        elif submission.is_excepted:\n",
    "                            all_failed_num += 1\n",
    "                            all_failed_dict[submit_key] = all_combination_dict[submit_key].copy()\n",
    "                            print('all_failed_num : ', all_failed_num)\n",
    "                            fail_group.add_nodes(submission)\n",
    "                            pop_list.append(submit_key)\n",
    "\n",
    "    #           -------------------------------------------------------------------------------\n",
    "                    garbage = [all_submission_dict.pop(pop_key) for pop_key in pop_list[:]]\n",
    "\n",
    "                    # To break while loop here\n",
    "                    if all_failed_num == max_fail_wc:\n",
    "                            if (all_submission_num - all_success_num + all_failed_num) == 0 :\n",
    "                                break\n",
    "            # To break for loop here\n",
    "            if all_failed_num == max_fail_wc:\n",
    "                if (all_submission_num - all_success_num + all_failed_num) == 0:\n",
    "                    break\n",
    "        ## To save the success dict in the Bunch_wc \n",
    "        self.All_success_dict = all_success_dict.copy()\n",
    "        self.All_resedue_dict = all_resedue_dict.copy()\n",
    "        self.All_failed_dict = all_failed_dict.copy()\n",
    "        self.Is_sumit_finished = True\n",
    "\n",
    "\n",
    "    def ReSubmit(self):\n",
    "        if self.Is_sumit_finished:\n",
    "            resedu_dict = sef.All_resedue_dict\n",
    "            self.All_combination_dict = resedu_dict.copy()\n",
    "            self.submit()\n",
    "## --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-arctic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-profile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-russell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-grammar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiiDA",
   "language": "python",
   "name": "aiida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
